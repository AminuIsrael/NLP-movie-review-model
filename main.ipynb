{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyprind, os, re, nltk, pickle,sqlite3\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = pyprind.ProgBar(50000)  #50000 number of documents to be read in \n",
    "labels = {'pos':1, 'neg':0}\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning text data\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text) #remove all html markup\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text) #keep emoticon character\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())+' '.join(emoticons).replace('-', '') #remove non-word character, convert to lower case \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adebimpe/.local/lib/python3.7/site-packages/tqdm/std.py:654: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 50296/50296 [00:08<00:00, 5992.06it/s]\n"
     ]
    }
   ],
   "source": [
    "#apply preprocessor function to the movie dataset\n",
    "tqdm.pandas()\n",
    "df = pd.read_csv(r'movie_data.csv')\n",
    "df['review'] = df['review'].progress_apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process document into tokens\n",
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word stemming; transfomring word to its root form\n",
    "#Note: In order to install the NLTK, you can simply execute pip install nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "#for example\n",
    "tokenizer_porter('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/adebimpe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'run', 'lot']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop word removal e.g. is, has etc.(there are about 127 stopwords in NLTK)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "#example\n",
    "[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:] if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25000 training and 25000 test sets\n",
    "X_train = df.loc[:25000, 'review'].values\n",
    "y_train = df.loc[:25000, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean and tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())+ ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we define a generator function, stream_docs, that reads in and returns one document at a time:\n",
    "def stream_docs(path):\n",
    "    with open(path, 'r', encoding='utf-8') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"An insane assault on viewers senses. This is a mish-mash of assorted Hindi and English movies - poorly done. The name carries over from a 70s\\' multi star cast, which the 2002 version also boasts of. The story is taken from the 70s\\' Sunil Dutt/Reena Roy starrer - \"\"Nagin\"\" and visual effects taken (a horrible attempt) from The Matrix, Terminator 2 and Mission Impossible II.<br /><br />Set in a college environment (Sunil Shetty, Akshaye Kumar, Manisha - college kids!!!???!!), Manisha Koirala is the victim, who mistakes a fatal assault on her by two students as a collective effort on the part of our heros. As it turns out Manisha is a Cobra (Nag) snake reborn as a girl in this life and her mate from the previous life, now a super powerful-all-and-any-shape-assuming (Ichadhari Nag) - Munish Kohli, is out looking for her in this life. Manisha appeals to him to avenge her violation and murder.<br /><br />So begins the mad killing spree, where the avenging lover starts singling each male of the group, with increasing powers and tricks with successive attempts. The effects are extremely cheap, with computer generated skeletons, morphing bodies and motorcycle stunts completing the farce.<br /><br />Carry over from Nagin includes Raj Babbar playing a catholic priest who provides temporary relief to our boys with a more \"\"Religiously correct\"\" multi-religion locket (the original Nagin only had an \"\"Om\"\") . Sunny Deol plays Manisha\\'s love interest in her current life and the ultimate saviour against the all powerful Munish Kohli.<br /><br />Music and songs are below average.<br /><br />Avoid if you don\\'t fancy cheap thrills.\"',\n",
       " 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify if the stream_docs function work \n",
    "output_path = r'movie_data.csv'\n",
    "next(stream_docs(path=output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a document stream from the stream_docs function and return a particular \n",
    "##number of documents specified by the size parameter\n",
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using hashing vectorizer for text processing\n",
    "#Note CountVectorizer is not used because it requires holding all vocabulary in memory\n",
    "#TfidfVectorizer is not used because it requires keeping all feature vectors of the\n",
    "#training data in memory to calculate inverse document frequencies.\n",
    "\n",
    "#We will use Hashingvectorizer, this is data independent\n",
    "#uisng SGD classifier algorithm\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', n_features=2**21, preprocessor=None,tokenizer=tokenizer)\n",
    "clf = SGDClassifier(loss='log', random_state=1)\n",
    "doc_stream = stream_docs(path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:38\n"
     ]
    }
   ],
   "source": [
    "#incremental training of 45000 documents\n",
    "pbar = pyprind.ProgBar(45)\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.870\n"
     ]
    }
   ],
   "source": [
    "#evaluate performance of the model with 5000 documents left\n",
    "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the model with the prediction \n",
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = os.path.join('movieclassifier', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "    pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'),'wb'), protocol=4)\n",
    "    pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'),protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adebimpe/.local/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#quick check if the pickled files and vectorizer.py are working\n",
    "from movieclassifier.vectorizer import vect\n",
    "clf = pickle.load(open(os.path.join('./movieclassifier/pkl_objects','classifier.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n",
      "Probability: 85.24%\n"
     ]
    }
   ],
   "source": [
    "label = {0:'negative', 1:'positive'}\n",
    "example = ['the movie was good,really enjoyed it']\n",
    "X = vect.transform(example)\n",
    "print('Prediction: %s\\nProbability: %.2f%%' %(label[clf.predict(X)[0]],np.max(clf.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
